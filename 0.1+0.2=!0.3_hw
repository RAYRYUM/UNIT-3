in python, upon entering this operation

0.1+0.2=0.3 

it returns it as FALSE
instead, when you calculate

0.1+0.2

it returns the sum of
0.30000000000000004

Why is this?

This problem originates from how python represents floating point numbers.
Most programming languages use 32 bit or 64 bit floats like python does. 
This controls how bits are used to represent numbers, in this case being 0.1 and 0.2.

these numbers are represented in three sections : 
sign - exponent - fraction
Sign dictates if the number is positive or negative. Then the exponent and fraction work in the same manner as a scientific notation

Here is an example of a 64-bit float :

https://github.com/RAYRYUM/UNIT-3/blob/main/64bit.png

To put it simply, the bits system uses this sientific formula to represent numbers :

(-1)^sign * 2^exponent-1023 * 1.fraction

0.2 is simply a multiple of 0.1 by 2, therefore it would only require for the exponent to be raised by one.
But 0.1 and 0.2 can quickly be noticed to be repeating decimals, because 2 is not a power of 10.
Because of the repeating decimals and the restriction of 52 bits for the fraction section of the total 64 bits, the decimal gets cut off at some point. 
Because of this, the number is rounded up incorrectly, therefore resulting the addition of 0.1 and 0.2 to be 0.30000000000000004.
